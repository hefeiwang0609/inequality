{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d1d8857",
   "metadata": {},
   "source": [
    "# ATE Robustness\n",
    "\n",
    "This notebook runs **robustness checks** for the baseline Causal Forest DML estimates (Digital literacy on Kakwani index).\n",
    "\n",
    "1. **Robustness 1** — K-fold cross-validation\n",
    "2. **Robustness 2** — number of trees\n",
    "3. **Robustness 3** — TOPSIS-entropy digital literacy\n",
    "4. **Robustness 4** — 1% winsorization \n",
    "5. **Robustness 5** — extra controls\n",
    "6. **Robustness 6** — Gini coefficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f419ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yhuang/anaconda3/envs/py312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from econml.dml import CausalForestDML\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore', category=DataConversionWarning)\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "OUTPUT_DIR = './results'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "CFDML_KW = {\n",
    "    \"discrete_treatment\": False,\n",
    "    \"n_estimators\": 500,\n",
    "    \"min_samples_split\": 50,\n",
    "    \"min_samples_leaf\": 18,\n",
    "    \"max_samples\": 0.4,\n",
    "    \"min_balancedness_tol\": 0.45,\n",
    "    \"honest\": True,\n",
    "    \"inference\": True,\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "def topsis_entropy_score(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"TOPSIS entropy-weighted composite score (0--1).\"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    norm_df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "    P = norm_df / norm_df.sum(axis=0)\n",
    "    eps = 1e-12\n",
    "    entropy = -np.nansum(P * np.log(P + eps), axis=0) / np.log(len(df))\n",
    "    redundancy = 1 - entropy\n",
    "    weights = redundancy / redundancy.sum()\n",
    "    weighted_df = norm_df * weights\n",
    "    ideal_best = weighted_df.max()\n",
    "    ideal_worst = weighted_df.min()\n",
    "    d_best = np.sqrt(((weighted_df - ideal_best) ** 2).sum(axis=1))\n",
    "    d_worst = np.sqrt(((weighted_df - ideal_worst) ** 2).sum(axis=1))\n",
    "    score = d_worst / (d_best + d_worst + eps)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5452dfe2",
   "metadata": {},
   "source": [
    "---\n",
    "## Load data and define variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e493b957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/data.xlsx')\n",
    "\n",
    "X_cols_name = [\n",
    "    'Gender', 'Age', 'Health status', 'Education level', 'Growing experience',\n",
    "    'Marital status', 'Growing area', 'Labourer', 'Production facility', 'Storage facility',\n",
    "    'Agricultural insurance', 'Loan', 'Social expenditure', 'Clan status', 'Natural disaster',\n",
    "    'Training', 'Brand label usage', 'Logistics convenience', 'City'\n",
    "]\n",
    "D_cols_name = ['Digital literacy', 'Digital device access', 'Digital information acquisition', 'Digital platform usage']\n",
    "Y_cols_name = ['kakwani_new', 'Household total income']\n",
    "M_cols_name = ['Online social network', 'Entrepreneurship']\n",
    "\n",
    "topsis_cols = ['Info search frequency', 'Info access types', 'Device count', 'Mobile phone bill', 'Online purchase', 'Online sales']\n",
    "topsis_cols = [c for c in topsis_cols if c in df.columns]\n",
    "if len(topsis_cols) >= 2:\n",
    "    df['Digital_literacy_TOPSIS'] = topsis_entropy_score(df[topsis_cols].apply(pd.to_numeric, errors='coerce'))\n",
    "else:\n",
    "    df['Digital_literacy_TOPSIS'] = np.nan\n",
    "\n",
    "X_df = df[X_cols_name]\n",
    "D_df = df[D_cols_name]\n",
    "Y_df = df[Y_cols_name]\n",
    "M_df = df[M_cols_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf58ac1",
   "metadata": {},
   "source": [
    "---\n",
    "## Preprocessing: X (one-hot City), Y, T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaa0563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_df.copy()\n",
    "categorical_cols = ['City']\n",
    "enc = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoded_region = enc.fit_transform(X[categorical_cols])\n",
    "encoded_region_df = pd.DataFrame(encoded_region, columns=enc.get_feature_names_out(categorical_cols))\n",
    "X = pd.concat([X.drop(columns=categorical_cols).reset_index(drop=True), encoded_region_df], axis=1)\n",
    "\n",
    "Y = Y_df['kakwani_new'].values\n",
    "T2 = D_df[['Digital literacy']].values\n",
    "T_topsis = df[['Digital_literacy_TOPSIS']].values if 'Digital_literacy_TOPSIS' in df.columns else T2\n",
    "\n",
    "X_train2, X_test2, T_train2, T_test2, Y_train2, Y_test2 = train_test_split(\n",
    "    X, T2, Y, test_size=0.4, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89938fe6",
   "metadata": {},
   "source": [
    "---\n",
    "# Six robustness checks\n",
    "\n",
    "## Robustness 1: K-fold cross-validation\n",
    "\n",
    "Vary the number of folds (K = 5, 8, 10) and report ATE and 95% CI per fold; then aggregate by K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "321dd24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Robustness check: K = 5 fold cross-validation\n",
      "  Fold 1/5: ATE = -0.1479, CI = (-0.2186, -0.0772), p = 0.0000\n",
      "  Fold 2/5: ATE = -0.1115, CI = (-0.1822, -0.0407), p = 0.0020\n",
      "  Fold 3/5: ATE = -0.0925, CI = (-0.1744, -0.0107), p = 0.0266\n",
      "  Fold 4/5: ATE = -0.1244, CI = (-0.1963, -0.0525), p = 0.0007\n",
      "  Fold 5/5: ATE = -0.1296, CI = (-0.2071, -0.0522), p = 0.0010\n",
      "\n",
      "Robustness check: K = 8 fold cross-validation\n",
      "  Fold 1/8: ATE = -0.1377, CI = (-0.2071, -0.0683), p = 0.0001\n",
      "  Fold 2/8: ATE = -0.1416, CI = (-0.2095, -0.0737), p = 0.0000\n",
      "  Fold 3/8: ATE = -0.1044, CI = (-0.1803, -0.0286), p = 0.0070\n",
      "  Fold 4/8: ATE = -0.1036, CI = (-0.1730, -0.0341), p = 0.0035\n",
      "  Fold 5/8: ATE = -0.1290, CI = (-0.1949, -0.0630), p = 0.0001\n",
      "  Fold 6/8: ATE = -0.1126, CI = (-0.1775, -0.0477), p = 0.0007\n",
      "  Fold 7/8: ATE = -0.1363, CI = (-0.2061, -0.0665), p = 0.0001\n",
      "  Fold 8/8: ATE = -0.1305, CI = (-0.2092, -0.0518), p = 0.0012\n",
      "\n",
      "Robustness check: K = 10 fold cross-validation\n",
      "  Fold 1/10: ATE = -0.1420, CI = (-0.2203, -0.0637), p = 0.0004\n",
      "  Fold 2/10: ATE = -0.1255, CI = (-0.1916, -0.0594), p = 0.0002\n",
      "  Fold 3/10: ATE = -0.1094, CI = (-0.1721, -0.0468), p = 0.0006\n",
      "  Fold 4/10: ATE = -0.1297, CI = (-0.2039, -0.0555), p = 0.0006\n",
      "  Fold 5/10: ATE = -0.1096, CI = (-0.1874, -0.0318), p = 0.0058\n",
      "  Fold 6/10: ATE = -0.0948, CI = (-0.1697, -0.0198), p = 0.0132\n",
      "  Fold 7/10: ATE = -0.1101, CI = (-0.1806, -0.0397), p = 0.0022\n",
      "  Fold 8/10: ATE = -0.1273, CI = (-0.1983, -0.0564), p = 0.0004\n",
      "  Fold 9/10: ATE = -0.1343, CI = (-0.2107, -0.0579), p = 0.0006\n",
      "  Fold 10/10: ATE = -0.1265, CI = (-0.1963, -0.0566), p = 0.0004\n",
      "\n",
      "Saved: CFDML_kfold_robustness_results.csv\n"
     ]
    }
   ],
   "source": [
    "kf_list = [5, 8, 10]\n",
    "robust_results = []\n",
    "\n",
    "for K in kf_list:\n",
    "    print(f\"\\nRobustness check: K = {K} fold cross-validation\")\n",
    "    kf = KFold(n_splits=K, shuffle=True, random_state=42)\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "        X_train_k, X_test_k = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        T_train_k, T_test_k = T2[train_idx], T2[test_idx]\n",
    "        Y_train_k, Y_test_k = Y[train_idx], Y[test_idx]\n",
    "\n",
    "        model_y_k = RandomForestRegressor(n_estimators=100, min_samples_leaf=10, random_state=42)\n",
    "        model_t_k = RandomForestRegressor(n_estimators=100, min_samples_leaf=10, random_state=42)\n",
    "        est_k = CausalForestDML(model_y=model_y_k, model_t=model_t_k, **CFDML_KW)\n",
    "        est_k.fit(Y_train_k, T_train_k, X=X_train_k)\n",
    "\n",
    "        te_pred_k = est_k.const_marginal_effect(X_test_k)\n",
    "        te_lo_k, te_hi_k = est_k.const_marginal_effect_interval(X_test_k)\n",
    "        avg_effect_k = te_pred_k.mean()\n",
    "        avg_ci_lo_k = te_lo_k.mean()\n",
    "        avg_ci_hi_k = te_hi_k.mean()\n",
    "        stderr_k = (avg_ci_hi_k - avg_ci_lo_k) / (2 * 1.96)\n",
    "        z_value_k = avg_effect_k / stderr_k\n",
    "        p_value_k = 2 * (1 - norm.cdf(abs(z_value_k)))\n",
    "\n",
    "        print(f\"  Fold {fold+1}/{K}: ATE = {avg_effect_k:.4f}, CI = ({avg_ci_lo_k:.4f}, {avg_ci_hi_k:.4f}), p = {p_value_k:.4f}\")\n",
    "        robust_results.append({\n",
    "            \"K\": K, \"fold\": fold + 1, \"ATE\": avg_effect_k, \"StdErr\": stderr_k,\n",
    "            \"CI_low\": avg_ci_lo_k, \"CI_high\": avg_ci_hi_k, \"p_value\": p_value_k\n",
    "        })\n",
    "\n",
    "robust_df = pd.DataFrame(robust_results)\n",
    "robust_df.to_csv(os.path.join(OUTPUT_DIR, \"CFDML_kfold_robustness_results.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "print(\"\\nSaved: CFDML_kfold_robustness_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19d8e536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary by K:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>ATE_mean</th>\n",
       "      <th>StdErr_mean</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.121184</td>\n",
       "      <td>0.038028</td>\n",
       "      <td>0.001439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.124459</td>\n",
       "      <td>0.035840</td>\n",
       "      <td>0.000515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.120920</td>\n",
       "      <td>0.036821</td>\n",
       "      <td>0.001023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    K  ATE_mean  StdErr_mean   p_value\n",
       "0   5 -0.121184     0.038028  0.001439\n",
       "1   8 -0.124459     0.035840  0.000515\n",
       "2  10 -0.120920     0.036821  0.001023"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_by_K = []\n",
    "for K_val in sorted(robust_df['K'].unique()):\n",
    "    df_k = robust_df[robust_df['K'] == K_val]\n",
    "    ate_mean = df_k['ATE'].mean()\n",
    "    stderr_mean = df_k['StdErr'].mean()\n",
    "    z_val = ate_mean / stderr_mean\n",
    "    p_val = 2 * (1 - norm.cdf(abs(z_val)))\n",
    "    summary_by_K.append({\"K\": K_val, \"ATE_mean\": ate_mean, \"StdErr_mean\": stderr_mean, \"p_value\": p_val})\n",
    "summary_df = pd.DataFrame(summary_by_K)\n",
    "summary_df.to_csv(os.path.join(OUTPUT_DIR, \"CFDML_kfold_summary_by_K.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Summary by K:\")\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734f5043",
   "metadata": {},
   "source": [
    "## Robustness 2: Number of trees\n",
    "\n",
    "Vary `n_estimators` (600, 800, 1000) and report ATE and 95% CI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8333bb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Robustness check: n_estimators = 600\n",
      "  n_estimators = 600: ATE = -0.1435, CI = (-0.2154, -0.0715), p = 0.0001\n",
      "\n",
      "Robustness check: n_estimators = 800\n",
      "  n_estimators = 800: ATE = -0.1444, CI = (-0.2134, -0.0753), p = 0.0000\n",
      "\n",
      "Robustness check: n_estimators = 1000\n",
      "  n_estimators = 1000: ATE = -0.1453, CI = (-0.2140, -0.0767), p = 0.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>ATE</th>\n",
       "      <th>StdErr</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>-0.143450</td>\n",
       "      <td>0.036712</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>800</td>\n",
       "      <td>-0.144363</td>\n",
       "      <td>0.035239</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>-0.145342</td>\n",
       "      <td>0.035035</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators       ATE    StdErr   p_value\n",
       "0           600 -0.143450  0.036712  0.000093\n",
       "1           800 -0.144363  0.035239  0.000042\n",
       "2          1000 -0.145342  0.035035  0.000033"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree_nums = [600, 800, 1000]\n",
    "robust_tree_results = []\n",
    "\n",
    "for n_tree in tree_nums:\n",
    "    print(f\"\\nRobustness check: n_estimators = {n_tree}\")\n",
    "    model_y_tree = RandomForestRegressor(n_estimators=100, min_samples_leaf=10, random_state=42)\n",
    "    model_t_tree = RandomForestRegressor(n_estimators=100, min_samples_leaf=10, random_state=42)\n",
    "    est_tree = CausalForestDML(\n",
    "        model_y=model_y_tree, model_t=model_t_tree,\n",
    "        n_estimators=n_tree, min_samples_split=50, min_samples_leaf=18, max_samples=0.4,\n",
    "        min_balancedness_tol=0.45, honest=True, inference=True, discrete_treatment=False, random_state=42\n",
    "    )\n",
    "    est_tree.fit(Y_train2, T_train2, X=X_train2)\n",
    "\n",
    "    te_pred_tree = est_tree.const_marginal_effect(X_test2)\n",
    "    te_lo_tree, te_hi_tree = est_tree.const_marginal_effect_interval(X_test2)\n",
    "    avg_effect_tree = te_pred_tree.mean()\n",
    "    avg_ci_lo_tree = te_lo_tree.mean()\n",
    "    avg_ci_hi_tree = te_hi_tree.mean()\n",
    "    stderr_tree = (avg_ci_hi_tree - avg_ci_lo_tree) / (2 * 1.96)\n",
    "    z_value_tree = avg_effect_tree / stderr_tree\n",
    "    p_value_tree = 2 * (1 - norm.cdf(abs(z_value_tree)))\n",
    "\n",
    "    print(f\"  n_estimators = {n_tree}: ATE = {avg_effect_tree:.4f}, CI = ({avg_ci_lo_tree:.4f}, {avg_ci_hi_tree:.4f}), p = {p_value_tree:.4f}\")\n",
    "    robust_tree_results.append({\n",
    "        \"n_estimators\": n_tree, \"ATE\": avg_effect_tree, \"StdErr\": stderr_tree,\n",
    "        \"p_value\": p_value_tree\n",
    "    })\n",
    "\n",
    "robust_tree_df = pd.DataFrame(robust_tree_results)\n",
    "robust_tree_df.to_csv(os.path.join(OUTPUT_DIR, \"CFDML_tree_robustness_results.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "display(robust_tree_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba69904",
   "metadata": {},
   "source": [
    "## Robustness 3: TOPSIS-entropy digital literacy\n",
    "\n",
    "Use the TOPSIS-entropy composite \"Digital literacy\" as treatment instead of the original index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244129e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Robustness 3] Treatment = TOPSIS-entropy digital literacy\n",
      "  ATE = -0.1213, StdErr = 0.0276, p = 0.0000\n",
      "Saved: CFDML_topsis_robustness_results.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[Robustness 3] Treatment = TOPSIS-entropy digital literacy\")\n",
    "\n",
    "X_train_top, X_test_top, T_train_top, T_test_top, Y_train_top, Y_test_top = train_test_split(\n",
    "    X, T_topsis, Y, test_size=0.4, random_state=42\n",
    ")\n",
    "model_y_top = RandomForestRegressor(n_estimators=100, min_samples_leaf=10, random_state=42)\n",
    "model_t_top = RandomForestRegressor(n_estimators=100, min_samples_leaf=10, random_state=42)\n",
    "est_top = CausalForestDML(model_y=model_y_top, model_t=model_t_top, **CFDML_KW)\n",
    "est_top.fit(Y_train_top, T_train_top, X=X_train_top)\n",
    "\n",
    "te_pred_top = est_top.const_marginal_effect(X_test_top)\n",
    "te_lo_top, te_hi_top = est_top.const_marginal_effect_interval(X_test_top)\n",
    "avg_effect_top = te_pred_top.mean()\n",
    "avg_ci_lo_top = te_lo_top.mean()\n",
    "avg_ci_hi_top = te_hi_top.mean()\n",
    "stderr_top = (avg_ci_hi_top - avg_ci_lo_top) / (2 * 1.96)\n",
    "z_value_top = avg_effect_top / stderr_top\n",
    "p_value_top = 2 * (1 - norm.cdf(abs(z_value_top)))\n",
    "\n",
    "print(f\"  ATE = {avg_effect_top:.4f}, StdErr = {stderr_top:.4f}, p = {p_value_top:.4f}\")\n",
    "pd.DataFrame([{\"ATE\": avg_effect_top, \"StdErr\": stderr_top, \"p_value\": p_value_top}]).to_csv(os.path.join(OUTPUT_DIR, \"CFDML_topsis_robustness_results.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved: CFDML_topsis_robustness_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b56bda7",
   "metadata": {},
   "source": [
    "## Robustness 4: 1% winsorization of outcome\n",
    "\n",
    "Winsorize Kakwani at 1% and 99% and re-estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "338686ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Robustness 4] Outcome = Kakwani_new, 1% winsorized\n",
      "  ATE = -0.1428, -0.0676), StdErr = 0.0384, p = 0.0002\n",
      "Saved: CFDML_winsor_robustness_results.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[Robustness 4] Outcome = Kakwani_new, 1% winsorized\")\n",
    "\n",
    "Y_winsor = np.clip(Y.copy(), np.percentile(Y, 1), np.percentile(Y, 99))\n",
    "X_train_win, X_test_win, T_train_win, T_test_win, Y_train_win, Y_test_win = train_test_split(\n",
    "    X, T2, Y_winsor, test_size=0.4, random_state=42\n",
    ")\n",
    "model_y_win = RandomForestRegressor(n_estimators=100, min_samples_leaf=10, random_state=42)\n",
    "model_t_win = RandomForestRegressor(n_estimators=100, min_samples_leaf=10, random_state=42)\n",
    "est_win = CausalForestDML(model_y=model_y_win, model_t=model_t_win, **CFDML_KW)\n",
    "est_win.fit(Y_train_win, T_train_win, X=X_train_win)\n",
    "\n",
    "te_pred_win = est_win.const_marginal_effect(X_test_win)\n",
    "te_lo_win, te_hi_win = est_win.const_marginal_effect_interval(X_test_win)\n",
    "avg_effect_win = te_pred_win.mean()\n",
    "avg_ci_lo_win = te_lo_win.mean()\n",
    "avg_ci_hi_win = te_hi_win.mean()\n",
    "stderr_win = (avg_ci_hi_win - avg_ci_lo_win) / (2 * 1.96)\n",
    "p_value_win = 2 * (1 - norm.cdf(abs(avg_effect_win / stderr_win)))\n",
    "\n",
    "print(f\"  ATE = {avg_effect_win:.4f}, {avg_ci_hi_win:.4f}), StdErr = {stderr_win:.4f}, p = {p_value_win:.4f}\")\n",
    "pd.DataFrame([{\"ATE\": avg_effect_win, \"StdErr\": stderr_win, \"p_value\": p_value_win}]).to_csv(os.path.join(OUTPUT_DIR, \"CFDML_winsor_robustness_results.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved: CFDML_winsor_robustness_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4885e1",
   "metadata": {},
   "source": [
    "## Robustness 5: Extra controls\n",
    "\n",
    "Add \"Nonfarm employment\" and \"Household size\" to the control set and re-estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78bf2fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Robustness 5] Extra controls: Nonfarm employment, Household size\n",
      "  ATE = -0.1397, StdErr = 0.0381, p = 0.0002\n",
      "Saved: CFDML_extra_controls_robustness_results.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[Robustness 5] Extra controls: Nonfarm employment, Household size\")\n",
    "\n",
    "extra_cols = [c for c in ['Nonfarm employment', 'Household size'] if c in df.columns]\n",
    "X_cols_name_extra = X_cols_name + extra_cols\n",
    "X_df_extra = df[[c for c in X_cols_name_extra if c in df.columns]]\n",
    "X_extra = X_df_extra.copy()\n",
    "enc_extra = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoded_extra = enc_extra.fit_transform(X_extra[categorical_cols])\n",
    "encoded_extra_df = pd.DataFrame(encoded_extra, columns=enc_extra.get_feature_names_out(categorical_cols))\n",
    "X_extra = pd.concat([X_extra.drop(columns=categorical_cols).reset_index(drop=True), encoded_extra_df], axis=1)\n",
    "\n",
    "X_train_extra, X_test_extra, T_train_extra, T_test_extra, Y_train_extra, Y_test_extra = train_test_split(\n",
    "    X_extra, T2, Y, test_size=0.4, random_state=42\n",
    ")\n",
    "model_y_extra = RandomForestRegressor(n_estimators=100, min_samples_leaf=10, random_state=42)\n",
    "model_t_extra = RandomForestRegressor(n_estimators=100, min_samples_leaf=10, random_state=42)\n",
    "est_extra = CausalForestDML(model_y=model_y_extra, model_t=model_t_extra, **CFDML_KW)\n",
    "est_extra.fit(Y_train_extra, T_train_extra, X=X_train_extra)\n",
    "\n",
    "te_pred_extra = est_extra.const_marginal_effect(X_test_extra)\n",
    "te_lo_extra, te_hi_extra = est_extra.const_marginal_effect_interval(X_test_extra)\n",
    "avg_effect_extra = te_pred_extra.mean()\n",
    "avg_ci_lo_extra = te_lo_extra.mean()\n",
    "avg_ci_hi_extra = te_hi_extra.mean()\n",
    "stderr_extra = (avg_ci_hi_extra - avg_ci_lo_extra) / (2 * 1.96)\n",
    "p_value_extra = 2 * (1 - norm.cdf(abs(avg_effect_extra / stderr_extra)))\n",
    "\n",
    "print(f\"  ATE = {avg_effect_extra:.4f}, StdErr = {stderr_extra:.4f}, p = {p_value_extra:.4f}\")\n",
    "pd.DataFrame([{\"ATE\": avg_effect_extra, \"StdErr\": stderr_extra, \"p_value\": p_value_extra}]).to_csv(os.path.join(OUTPUT_DIR, \"CFDML_extra_controls_robustness_results.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved: CFDML_extra_controls_robustness_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6b455cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marital status binarized\n",
      "  ATE = -0.1448, 95% CI = (-0.2197, -0.0698), StdErr = 0.0382, p = 0.0002\n",
      "Saved: CFDML_T2_marital_robustness_results.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Marital status binarized\")\n",
    "\n",
    "X_df_marital = X_df.copy()\n",
    "ms = X_df_marital['Marital status']\n",
    "X_df_marital['Marital status'] = np.where(ms == 1, 1, 0)\n",
    "\n",
    "X_marital = X_df_marital.copy()\n",
    "enc_marital = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoded_marital = enc_marital.fit_transform(X_marital[categorical_cols])\n",
    "encoded_marital_df = pd.DataFrame(encoded_marital, columns=enc_marital.get_feature_names_out(categorical_cols))\n",
    "X_marital = pd.concat([X_marital.drop(columns=categorical_cols).reset_index(drop=True), encoded_marital_df], axis=1)\n",
    "\n",
    "X_train_m, X_test_m, T_train_m, T_test_m, Y_train_m, Y_test_m = train_test_split(\n",
    "    X_marital, T2, Y, test_size=0.4, random_state=42\n",
    ")\n",
    "model_y_m = RandomForestRegressor(n_estimators=100, min_samples_leaf=10, random_state=42)\n",
    "model_t_m = RandomForestRegressor(n_estimators=100, min_samples_leaf=10, random_state=42)\n",
    "est2_marital = CausalForestDML(model_y=model_y_m, model_t=model_t_m, **CFDML_KW)\n",
    "est2_marital.fit(Y_train_m, T_train_m, X=X_train_m)\n",
    "\n",
    "te_pred_m = est2_marital.const_marginal_effect(X_test_m)\n",
    "te_lo_m, te_hi_m = est2_marital.const_marginal_effect_interval(X_test_m, alpha=0.05)\n",
    "avg_effect_m = te_pred_m.mean(axis=0)[0]\n",
    "avg_ci_lo_m = te_lo_m.mean(axis=0)[0]\n",
    "avg_ci_hi_m = te_hi_m.mean(axis=0)[0]\n",
    "stderr_m = (avg_ci_hi_m - avg_ci_lo_m) / (2 * 1.96)\n",
    "p_value_m = 2 * (1 - norm.cdf(abs(avg_effect_m / stderr_m))) if stderr_m > 0 else np.nan\n",
    "\n",
    "print(f\"  ATE = {avg_effect_m:.4f}, 95% CI = ({avg_ci_lo_m:.4f}, {avg_ci_hi_m:.4f}), StdErr = {stderr_m:.4f}, p = {p_value_m:.4f}\")\n",
    "pd.DataFrame([{\n",
    "    \"ATE\": avg_effect_m, \"StdErr\": stderr_m, \"95%CI_low\": avg_ci_lo_m, \"95%CI_high\": avg_ci_hi_m,\n",
    "    \"p_value\": p_value_m, \"note\": \"Marital status binarized (1 kept, >1 -> 0)\"\n",
    "}]).to_csv(os.path.join(OUTPUT_DIR, \"CFDML_T2_marital_robustness_results.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved: CFDML_T2_marital_robustness_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628e20cf",
   "metadata": {},
   "source": [
    "---\n",
    "# Robustness 6: Gini coefficient robustness\n",
    "\n",
    "Use Gini coefficient as the outcome instead of Kakwani."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6b51f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_coefficient(y):\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    y = y[np.isfinite(y)]\n",
    "    y = y[y >= 0]\n",
    "    n = len(y)\n",
    "    if n == 0:\n",
    "        return np.nan\n",
    "    mu = y.mean()\n",
    "    if mu == 0:\n",
    "        return 0.0\n",
    "    y_sorted = np.sort(y)\n",
    "    idx = np.arange(1, n + 1)\n",
    "    g = (2.0 * np.sum(idx * y_sorted)) / (n * np.sum(y_sorted)) - (n + 1.0) / n\n",
    "    return float(g)\n",
    "\n",
    "def add_leave_one_out_ineq(g, income_col='Household total income'):\n",
    "    y = g[income_col].values.astype(float)\n",
    "    n = len(y)\n",
    "    gini_loo = np.full(n, np.nan, dtype=float)\n",
    "    if n <= 1:\n",
    "        g['Gini_loo'] = gini_loo\n",
    "        return g\n",
    "    for i in range(n):\n",
    "        gini_loo[i] = gini_coefficient(np.delete(y, i))\n",
    "    g['Gini_loo'] = gini_loo\n",
    "    return g\n",
    "\n",
    "income_col = 'Household total income'\n",
    "city_col = 'City'\n",
    "df_gini = df.copy()\n",
    "if city_col in df_gini.columns and income_col in df_gini.columns:\n",
    "    city_saved = df_gini[city_col].copy()\n",
    "    df_gini = df_gini.groupby(city_col, group_keys=False).apply(lambda g: add_leave_one_out_ineq(g, income_col))\n",
    "    df_gini[city_col] = city_saved\n",
    "    Y_gini = df_gini['Gini_loo'].values.reshape(-1, 1)\n",
    "else:\n",
    "    Y_gini = np.full((len(df_gini), 1), np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61f67c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Digital literacy on Gini :\n",
      "  ATE = -0.009452,  StdErr = 0.003733, p = 0.011334003280170313\n"
     ]
    }
   ],
   "source": [
    "def run_model_gini(Y, X, T2, label='Gini'):\n",
    "    Y = np.asarray(Y).ravel()\n",
    "    valid = np.isfinite(Y)\n",
    "    if valid.sum() < 50:\n",
    "        print(\"Too few valid Gini values; skipping.\")\n",
    "        return None, None, None\n",
    "    X_v, T_v, Y_v = X.values[valid], T2[valid], Y[valid]\n",
    "    X_train2, X_test2, T_train2, T_test2, Y_train2, Y_test2 = train_test_split(\n",
    "        X_v, T_v, Y_v, test_size=0.3, random_state=42\n",
    "    )\n",
    "    model_y2 = RandomForestRegressor(n_estimators=100, min_samples_leaf=20, random_state=42)\n",
    "    model_t2 = RandomForestRegressor(n_estimators=100, min_samples_leaf=20, random_state=42)\n",
    "    est2 = CausalForestDML(\n",
    "        model_y=model_y2, model_t=model_t2, discrete_treatment=False,\n",
    "        n_estimators=500, min_samples_split=30, min_samples_leaf=35, max_samples=0.25,\n",
    "        honest=True, inference=True, random_state=42\n",
    "    )\n",
    "    est2.fit(Y_train2, T_train2, X=X_train2)\n",
    "    te_pred2 = est2.const_marginal_effect(X_test2)\n",
    "    te_lo2, te_hi2 = est2.const_marginal_effect_interval(X_test2, alpha=0.05)\n",
    "    avg_effect2 = np.asarray(te_pred2.mean(axis=0)).ravel()[0]\n",
    "    avg_ci_lo2 = np.asarray(te_lo2.mean(axis=0)).ravel()[0]\n",
    "    avg_ci_hi2 = np.asarray(te_hi2.mean(axis=0)).ravel()[0]\n",
    "    stderr2 = (avg_ci_hi2 - avg_ci_lo2) / (2 * 1.96)\n",
    "    z_value2 = avg_effect2 / stderr2 if stderr2 != 0 else np.nan\n",
    "    p_value2 = (2 * (1 - norm.cdf(abs(z_value2)))) if np.isfinite(z_value2) else np.nan\n",
    "    print(f\"\\nDigital literacy on {label} :\")\n",
    "    print(f\"  ATE = {avg_effect2:.6f},  StdErr = {stderr2:.6f}, p = {p_value2}\")\n",
    "    return est2, te_pred2, (te_lo2, te_hi2)\n",
    "\n",
    "X_df_gini = df_gini[X_cols_name]\n",
    "X_gini = X_df_gini.copy()\n",
    "enc_gini = OneHotEncoder(drop='first', sparse_output=False)\n",
    "enc_city = enc_gini.fit_transform(X_gini[categorical_cols])\n",
    "enc_city_df = pd.DataFrame(enc_city, columns=enc_gini.get_feature_names_out(categorical_cols))\n",
    "X_gini = pd.concat([X_gini.drop(columns=categorical_cols).reset_index(drop=True), enc_city_df], axis=1)\n",
    "\n",
    "est2_gini, te_gini, ci_gini = run_model_gini(Y_gini, X_gini, T2, label='Gini')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
