{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DML-IV: Instrumental Variable with Base Station Count\n",
    "\n",
    "This notebook addresses **endogeneity** using **Double Machine Learning with Instrumental Variables (DMLIV)**. The instrument is **total number of base stations**.\n",
    "\n",
    "- **Treatment (T)**: Digital literacy (first-level index).\n",
    "- **Outcome (Y)**: `kakwani_new`.\n",
    "- **Instrument (Z)**: Base station count.\n",
    "- **Covariates (X)**: Control variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup: Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "619bd65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yhuang/anaconda3/envs/py312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from econml.iv.dml import DMLIV\n",
    "from econml.sklearn_extensions.linear_model import StatsModelsLinearRegression\n",
    "from scipy.stats import norm\n",
    "from statsmodels.api import OLS, add_constant\n",
    "\n",
    "warnings.filterwarnings('ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings('ignore', message='.*nonzero intercept.*', module='econml')\n",
    "\n",
    "OUPUT_DIR = \"./results\"\n",
    "if not os.path.exists(OUPUT_DIR):\n",
    "    os.makedirs(OUPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1485f1de",
   "metadata": {},
   "source": [
    "---\n",
    "## Load data and define variables\n",
    "\n",
    "Data are read from `data/data.xlsx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "869b95fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size after dropping missing IV: 1382\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('data/data.xlsx')\n",
    "\n",
    "X_cols_name = [\n",
    "    'Gender', 'Age', 'Health status', 'Education level', 'Growing experience',\n",
    "    'Marital status', 'Growing area', 'Labourer', 'Production facility', 'Storage facility',\n",
    "    'Agricultural insurance', 'Loan', 'Social expenditure', 'Clan status', 'Natural disaster',\n",
    "    'Training', 'Brand label usage', 'Logistics convenience', 'City'\n",
    "]\n",
    "D_cols_name = [\n",
    "    'Digital literacy', 'Digital platform usage', 'Digital information acquisition', 'Digital platform usage'\n",
    "]\n",
    "Y_cols_name = ['kakwani_new', 'Household total income']\n",
    "M_cols_name = ['Online social network', 'Entrepreneurship']\n",
    "IV_cols_name = ['Base station count']\n",
    "\n",
    "# Drop rows with missing instrument (required for IV identification)\n",
    "df = df.dropna(subset=IV_cols_name).copy()\n",
    "print(f\"Sample size after dropping missing IV: {len(df)}\")\n",
    "\n",
    "X_df = df[X_cols_name]\n",
    "D_df = df[D_cols_name]\n",
    "Y_df = df[Y_cols_name]\n",
    "M_df = df[M_cols_name]\n",
    "IV_df = df[IV_cols_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a0019e",
   "metadata": {},
   "source": [
    "---\n",
    "## Preprocessing: encodings\n",
    "\n",
    "- **Covariates (X)**: One-hot encode `City`, keep other controls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "854406a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment T standardized: mean = 0.2674, std = 0.2373\n"
     ]
    }
   ],
   "source": [
    "X = X_df.copy()\n",
    "categorical_cols = ['City']\n",
    "enc = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoded_region = enc.fit_transform(X[categorical_cols])\n",
    "encoded_region_df = pd.DataFrame(encoded_region, columns=enc.get_feature_names_out(categorical_cols))\n",
    "X = pd.concat([X.drop(columns=categorical_cols).reset_index(drop=True), encoded_region_df], axis=1)\n",
    "\n",
    "Z = IV_df.copy()\n",
    "Z_encoded = OneHotEncoder(drop='first', sparse_output=False).fit_transform(Z)\n",
    "Z_encoded_df = pd.DataFrame(Z_encoded, columns=[f'Base_station_{i}' for i in range(Z_encoded.shape[1])])\n",
    "\n",
    "Y = Y_df['kakwani_new'].values\n",
    "\n",
    "USE_T_STANDARDIZE = True\n",
    "T_std = None\n",
    "if USE_T_STANDARDIZE:\n",
    "    T2_raw = D_df['Digital literacy'].values.copy()\n",
    "    T_mean, T_std = T2_raw.mean(), T2_raw.std()\n",
    "    if T_std < 1e-10:\n",
    "        T_std = 1.0\n",
    "    T2 = ((T2_raw - T_mean) / T_std).reshape(-1, 1)\n",
    "    print(f\"Treatment T standardized: mean = {T_mean:.4f}, std = {T_std:.4f}\")\n",
    "else:\n",
    "    T2 = D_df['Digital literacy'].values.reshape(-1, 1)\n",
    "\n",
    "Z_one_hot = Z_encoded_df.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dde3747",
   "metadata": {},
   "source": [
    "---\n",
    "## DMLIV model\n",
    "\n",
    "We fit **DMLIV** and first-stage strength is summarized by F-statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cb8e455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<econml.iv.dml._dml.DMLIV at 0x166346e10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, T_train, T_test, Y_train, Y_test, Z_train, Z_test = train_test_split(\n",
    "    X, T2, Y, Z_one_hot, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "HYPERPARAMS_DMLIV = {\n",
    "    \"n_estimators\": 200,\n",
    "    \"min_samples_split\": 10,\n",
    "    \"min_samples_leaf\": 15,\n",
    "    \"max_samples\": 0.35,\n",
    "    \"random_state\": 2,\n",
    "}\n",
    "\n",
    "X_train_arr = np.asarray(X_train)\n",
    "Z_train_arr = np.asarray(Z_train)\n",
    "\n",
    "model_y_xw  = RandomForestRegressor(**HYPERPARAMS_DMLIV)\n",
    "model_t_xw  = RandomForestRegressor(**HYPERPARAMS_DMLIV)\n",
    "model_t_xwz = RandomForestRegressor(**HYPERPARAMS_DMLIV)\n",
    "\n",
    "est = DMLIV(\n",
    "    model_y_xw=model_y_xw,\n",
    "    model_t_xw=model_t_xw,\n",
    "    model_t_xwz=model_t_xwz,\n",
    "    model_final=StatsModelsLinearRegression(fit_intercept=True),\n",
    "    discrete_instrument=False,\n",
    "    discrete_treatment=False,\n",
    "    random_state=HYPERPARAMS_DMLIV[\"random_state\"]\n",
    ")\n",
    "est.fit(Y=Y_train, T=T_train, Z=Z_train, X=X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153b4e09",
   "metadata": {},
   "source": [
    "---\n",
    "## First-stage strength and IV-ATE\n",
    "\n",
    "We compute F-statistic for the first stage. Then we estimate IV-ATE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "446bff35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F = 15.37\n",
      "IV-ATE (effect per 1 unit Digital literacy on Kakwani):\n",
      "  IV-ATE ≈ -0.1008, 95% CI = (-0.1597, -0.0419), p ≈ 0.0008011254790094569\n"
     ]
    }
   ],
   "source": [
    "T_hat = model_t_xwz.fit(np.hstack([X_train_arr, Z_train_arr]), T_train).predict(\n",
    "    np.hstack([X_train_arr, Z_train_arr])\n",
    ")\n",
    "r2 = r2_score(T_train, T_hat)\n",
    "T_model = OLS(T_train, add_constant(np.hstack([X_train_arr, Z_train_arr]))).fit()\n",
    "f_stat = T_model.fvalue\n",
    "\n",
    "te_pred = np.asarray(est.effect(X_test)).ravel()\n",
    "avg_effect = np.mean(te_pred)\n",
    "n_test = len(te_pred)\n",
    "stderr = np.std(te_pred, ddof=1) / np.sqrt(n_test) if n_test > 1 else np.nan\n",
    "if stderr == 0 or np.isnan(stderr):\n",
    "    stderr = np.nan\n",
    "    p_value = np.nan\n",
    "    ci_low = ci_high = avg_effect\n",
    "else:\n",
    "    z_value = avg_effect / stderr\n",
    "    p_value = 2 * (1 - norm.cdf(abs(z_value)))\n",
    "    ci_low = avg_effect - 1.96 * stderr\n",
    "    ci_high = avg_effect + 1.96 * stderr\n",
    "\n",
    "if USE_T_STANDARDIZE and T_std is not None:\n",
    "    avg_effect_report = avg_effect * T_std\n",
    "    stderr_report = stderr * T_std if np.isfinite(stderr) else np.nan\n",
    "    ci_low_report, ci_high_report = ci_low * T_std, ci_high * T_std\n",
    "else:\n",
    "    avg_effect_report, stderr_report = avg_effect, stderr\n",
    "    ci_low_report, ci_high_report = ci_low, ci_high\n",
    "\n",
    "print( \"F =\", round(f_stat, 2))\n",
    "print(\"IV-ATE (effect per 1 unit Digital literacy on Kakwani):\")\n",
    "print(f\"  IV-ATE ≈ {avg_effect_report:.4f}, 95% CI = ({ci_low_report:.4f}, {ci_high_report:.4f}), p ≈ {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3741cf2f",
   "metadata": {},
   "source": [
    "---\n",
    "## Save and display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73b63341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to DMLIV_BaseStation_results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IV_ATE</th>\n",
       "      <th>StdErr</th>\n",
       "      <th>p_value</th>\n",
       "      <th>F_stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.10076</td>\n",
       "      <td>0.030056</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>15.36519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    IV_ATE    StdErr   p_value    F_stat\n",
       "0 -0.10076  0.030056  0.000801  15.36519"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = [{\n",
    "    \"IV_ATE\": avg_effect_report,\n",
    "    \"StdErr\": stderr_report,\n",
    "    \"p_value\": p_value,\n",
    "    \"F_stat\": f_stat,\n",
    "}]\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(os.path.join(OUPUT_DIR, \"DMLIV_BaseStation_results.csv\"), index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Results saved to DMLIV_BaseStation_results.csv\")\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
